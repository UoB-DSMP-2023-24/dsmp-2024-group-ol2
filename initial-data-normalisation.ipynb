{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from utils import aws # used to create aws session and load parquet \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast \n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample data from S3\n",
    "\n",
    "Make sure to update credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sample lob from s3 to a dask dataframe\n",
    "samp_lob_ddf = aws.load_s3_file_as_ddf(\"s3://dsmp-ol2/processed-data/lob_sample_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dask datafram to a pandas dataframe\n",
    "samp_lob = samp_lob_ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mid_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.333</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[800, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[799, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[798, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>399.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp Exchange       Bid         Ask        Date  Mid_Price\n",
       "0      0.000    Exch0        []          []  2025-01-02        NaN\n",
       "1      0.279    Exch0  [[1, 6]]          []  2025-01-02        NaN\n",
       "2      1.333    Exch0  [[1, 6]]  [[800, 1]]  2025-01-02      400.5\n",
       "3      1.581    Exch0  [[1, 6]]  [[799, 1]]  2025-01-02      400.0\n",
       "4      1.643    Exch0  [[1, 6]]  [[798, 1]]  2025-01-02      399.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_lob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise the Mid-Price using z-score\n",
    "\n",
    "Based on the research done on normaliation, a common technique used when analysing LOB data is z-score. As trends change across time in finace, it is common place to use dynamic normalisation. In the case of z-score this means taking the mean and standard deviation of a previous period (often the previous day) and using that as the measure to caluclate z-score. The draw back of this is that the first day's data is lost as there is no previous day to normalise against.\n",
    "\n",
    "Below uses a dynamic z-score to normalise the Mid-Price. Additional features can be added for normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'features_to_normalize' with the list of feature column names we want to normalize\n",
    "# Starting with just mid-price as an example\n",
    "features_to_normalize = ['Mid_Price']  # Replace with feature column names in the future\n",
    "\n",
    "for date in samp_lob['Date'].unique():\n",
    "    if date == samp_lob['Date'].min():  # Skip the first date since there's no previous day\n",
    "        continue\n",
    "    \n",
    "    prev_date = samp_lob[samp_lob['Date'] < date]['Date'].max()  # Find the most recent previous date\n",
    "    \n",
    "    # Calculate mean and standard deviation for each feature for the previous day\n",
    "    prev_day_stats = samp_lob[samp_lob['Date'] == prev_date][features_to_normalize].mean()\n",
    "    prev_day_std = samp_lob[samp_lob['Date'] == prev_date][features_to_normalize].std()\n",
    "    \n",
    "    # Normalize the features for the current date using z-score with stats from the previous day\n",
    "    for feature in features_to_normalize:\n",
    "        normalized_feature = (samp_lob[samp_lob['Date'] == date][feature] - prev_day_stats[feature]) / prev_day_std[feature]\n",
    "        samp_lob.loc[samp_lob['Date'] == date, feature + 'z-score_normalized'] = normalized_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mid_Price</th>\n",
       "      <th>Mid_Pricez-score_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.333</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[800, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[799, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[798, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>399.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037929</th>\n",
       "      <td>30599.418</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [104, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [343, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037930</th>\n",
       "      <td>30599.449</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [99, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [343, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037931</th>\n",
       "      <td>30599.635</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [99, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037932</th>\n",
       "      <td>30599.697</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [249, 1], [99, 3], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037933</th>\n",
       "      <td>30599.728</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [320, 8], [249, 1], [99, 3], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037934 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Timestamp Exchange                                               Bid  \\\n",
       "0            0.000    Exch0                                                []   \n",
       "1            0.279    Exch0                                          [[1, 6]]   \n",
       "2            1.333    Exch0                                          [[1, 6]]   \n",
       "3            1.581    Exch0                                          [[1, 6]]   \n",
       "4            1.643    Exch0                                          [[1, 6]]   \n",
       "...            ...      ...                                               ...   \n",
       "1037929  30599.418    Exch0            [[323, 2], [104, 3], [63, 1], [44, 6]]   \n",
       "1037930  30599.449    Exch0             [[323, 2], [99, 3], [63, 1], [44, 6]]   \n",
       "1037931  30599.635    Exch0             [[323, 2], [99, 3], [63, 1], [44, 6]]   \n",
       "1037932  30599.697    Exch0            [[323, 2], [249, 1], [99, 3], [44, 6]]   \n",
       "1037933  30599.728    Exch0  [[323, 2], [320, 8], [249, 1], [99, 3], [44, 6]]   \n",
       "\n",
       "                                                       Ask        Date  \\\n",
       "0                                                       []  2025-01-02   \n",
       "1                                                       []  2025-01-02   \n",
       "2                                               [[800, 1]]  2025-01-02   \n",
       "3                                               [[799, 1]]  2025-01-02   \n",
       "4                                               [[798, 1]]  2025-01-02   \n",
       "...                                                    ...         ...   \n",
       "1037929  [[338, 1], [343, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037930  [[338, 1], [343, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037931  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037932  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037933  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "\n",
       "         Mid_Price  Mid_Pricez-score_normalized  \n",
       "0              NaN                          NaN  \n",
       "1              NaN                          NaN  \n",
       "2            400.5                          NaN  \n",
       "3            400.0                          NaN  \n",
       "4            399.5                          NaN  \n",
       "...            ...                          ...  \n",
       "1037929      330.5                     0.893131  \n",
       "1037930      330.5                     0.893131  \n",
       "1037931      330.5                     0.893131  \n",
       "1037932      330.5                     0.893131  \n",
       "1037933      330.5                     0.893131  \n",
       "\n",
       "[1037934 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Now the df contains normalized values for features based on z-score with stats from the previous day\n",
    "samp_lob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although z-score is a common normalisation technique a number of papers suggest that different models perform better with different normalisation techniques. Given data normalisation has such and impact on model performance it can be considered during model tuning to ensure the most performant method is selected.\n",
    "\n",
    "## Create a Normalisation Function\n",
    "\n",
    "Below takes the code above and uses it in a function where different normalisation techniques can be utilised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Extract z-score and min-max into separate functions that are called within normalisae features\n",
    "# TODO Add window size to determine the number of previous days to use in the normalisation\n",
    "# TODO Migrate this notebook to the model pipeline notebook\n",
    "\n",
    "def normalize_features(df, features_to_normalize, method='z-score'):\n",
    "    \"\"\"\n",
    "    Normalize features in the DataFrame based on the chosen method.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the LOB data and features.\n",
    "        features_to_normalize (list): List of feature column names to normalize.\n",
    "        method (str): Normalization method. Supported methods: 'z-score', 'min-max'. Defaults to 'z-score'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with normalized feature columns.\n",
    "    \"\"\"\n",
    "    for date in df['Date'].unique():\n",
    "        if date == df['Date'].min():  # Skip the first date since there's no previous day\n",
    "            continue\n",
    "        \n",
    "        prev_date = df[df['Date'] < date]['Date'].max()  # Find the most recent previous date\n",
    "        \n",
    "        # Normalize the features for the current date using the chosen method\n",
    "        for feature in features_to_normalize:\n",
    "            if method == 'z-score':\n",
    "                # Calculate mean and standard deviation for each feature for the previous day\n",
    "                prev_day_mean = df[df['Date'] == prev_date][feature].mean()\n",
    "                prev_day_std = df[df['Date'] == prev_date][feature].std()\n",
    "                # Calculate z-score for each feature\n",
    "                normalized_feature = (df[df['Date'] == date][feature] - prev_day_mean) / prev_day_std\n",
    "            elif method == 'min-max':\n",
    "                # Calculate min and max for each feature for the previous day\n",
    "                min_val = df[df['Date'] == prev_date][feature].min()\n",
    "                max_val = df[df['Date'] == prev_date][feature].max()\n",
    "                # Calculate min-max normalisation for each feature\n",
    "                normalized_feature = (df[df['Date'] == date][feature] - min_val) / (max_val - min_val)\n",
    "            elif method == 'decimal_scaling':\n",
    "                # Calculate max for each feature for the previous day\n",
    "                max_val = df[df['Date'] == prev_date][feature].max()\n",
    "                # Calculate the number of digits in the max_val\n",
    "                digits = len(str(abs(max_val)).split('.')[0])\n",
    "                # Calculate decimal scaling normalisation for each feature\n",
    "                normalized_feature = df[df['Date'] == date][feature] / 10**digits\n",
    "            elif method == 'robust_scaling':\n",
    "                # Calculate median and iqr for each feature for the previous day\n",
    "                prev_day_median = df[df['Date'] == prev_date][feature].median()\n",
    "                prev_day_quartiles = df[df['Date'] == prev_date][feature].quantile([0.25, 0.75]) # Upper and lower quartiles\n",
    "                prev_day_iqr = prev_day_quartiles[0.75] - prev_day_quartiles[0.25] # Inter quartile range\n",
    "                # Calculate z-score for each feature\n",
    "                normalized_feature = (df[df['Date'] == date][feature] - prev_day_median) / prev_day_iqr\n",
    "            elif method == 'sigmoid': # TODO check this calculation\n",
    "                # Calculate mean and standard deviation for each feature for the previous day\n",
    "                prev_day_mean = df[df['Date'] == prev_date][feature].mean()\n",
    "                prev_day_std = df[df['Date'] == prev_date][feature].std()\n",
    "                # Calculate sigmoid normalisation for each feature\n",
    "                normalized_feature = 1 / (1 + np.exp((-df[df['Date'] == date][feature] - prev_day_mean) / prev_day_std))\n",
    "            elif method == 'tanh': \n",
    "                # Calculate mean and standard deviation for each feature for the previous day\n",
    "                prev_day_mean = df[df['Date'] == prev_date][feature].mean()\n",
    "                prev_day_std = df[df['Date'] == prev_date][feature].std()\n",
    "                # Calculate tanh estimation for each feature\n",
    "                normalized_feature = 0.5*(np.tanh((0.01*(df[df['Date'] == date][feature] - prev_day_mean)) / prev_day_std))\n",
    "            elif method == 'mean':\n",
    "                # Calculate min, max and median for each feature for the previous day\n",
    "                prev_day_mean = df[df['Date'] == prev_date][feature].mean()\n",
    "                min_val = df[df['Date'] == prev_date][feature].min()\n",
    "                max_val = df[df['Date'] == prev_date][feature].max()\n",
    "                # Calculate min-max normalisation for each feature\n",
    "                normalized_feature = (df[df['Date'] == date][feature] - prev_day_mean) / (max_val - min_val)\n",
    "            elif method == 'median':\n",
    "                # Calculate median for each feature for the previous day\n",
    "                prev_day_median = df[df['Date'] == prev_date][feature].median()\n",
    "                # Calculate min-max normalisation for each feature\n",
    "                normalized_feature = (df[df['Date'] == date][feature] - min_val) / prev_day_median\n",
    "            elif method == 'max_absolute':\n",
    "                # Calculate max for each feature for the previous day\n",
    "                max_val = df[df['Date'] == prev_date][feature].max()\n",
    "                # Calculate min-max normalisation for each feature\n",
    "                normalized_feature = (df[df['Date'] == date][feature]) / max_val\n",
    "            # Store the normalized values in new columns\n",
    "            df.loc[df['Date'] == date, feature + '_' + method + '_normalized'] = normalized_feature\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmp-ol2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
