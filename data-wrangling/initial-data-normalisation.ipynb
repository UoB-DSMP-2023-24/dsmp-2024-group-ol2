{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from utils import aws # used to create aws session and load parquet \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast \n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample data from S3\n",
    "\n",
    "Make sure to update credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load sample lob from s3 to a dask dataframe\n",
    "samp_lob_ddf = aws.load_s3_file_as_ddf(\"s3://dsmp-ol2/processed-data/lob_sample_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dask datafram to a pandas dataframe\n",
    "samp_lob = samp_lob_ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mid_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.333</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[800, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[799, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[798, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>399.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp Exchange       Bid         Ask        Date  Mid_Price\n",
       "0      0.000    Exch0        []          []  2025-01-02        NaN\n",
       "1      0.279    Exch0  [[1, 6]]          []  2025-01-02        NaN\n",
       "2      1.333    Exch0  [[1, 6]]  [[800, 1]]  2025-01-02      400.5\n",
       "3      1.581    Exch0  [[1, 6]]  [[799, 1]]  2025-01-02      400.0\n",
       "4      1.643    Exch0  [[1, 6]]  [[798, 1]]  2025-01-02      399.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_lob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise the Mid-Price using z-score\n",
    "\n",
    "Based on the research done on normaliation, a common technique used when analysing LOB data is z-score. As trends change across time in finace, it is common place to use dynamic normalisation. In the case of z-score this means taking the mean and standard deviation of a previous period (often the previous day) and using that as the measure to caluclate z-score. The draw back of this is that the first day's data is lost as there is no previous day to normalise against.\n",
    "\n",
    "Below uses a dynamic z-score to normalise the Mid-Price. Additional features can be added for normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'features_to_normalise' with the list of feature column names we want to normalize\n",
    "# Starting with just mid-price as an example\n",
    "features_to_normalise = ['Mid_Price']  # Replace with feature column names in the future\n",
    "\n",
    "for date in samp_lob['Date'].unique():\n",
    "    if date == samp_lob['Date'].min():  # Skip the first date since there's no previous day\n",
    "        continue\n",
    "    \n",
    "    prev_date = samp_lob[samp_lob['Date'] < date]['Date'].max()  # Find the most recent previous date\n",
    "    \n",
    "    # Calculate mean and standard deviation for each feature for the previous day\n",
    "    prev_day_stats = samp_lob[samp_lob['Date'] == prev_date][features_to_normalise].mean()\n",
    "    prev_day_std = samp_lob[samp_lob['Date'] == prev_date][features_to_normalise].std()\n",
    "    \n",
    "    # Normalize the features for the current date using z-score with stats from the previous day\n",
    "    for feature in features_to_normalise:\n",
    "        normalised_feature = (samp_lob[samp_lob['Date'] == date][feature] - prev_day_stats[feature]) / prev_day_std[feature]\n",
    "        samp_lob.loc[samp_lob['Date'] == date, feature + 'z-score_normalised'] = normalised_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mid_Price</th>\n",
       "      <th>Mid_Pricez-score_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.333</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[800, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[799, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[798, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>399.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037929</th>\n",
       "      <td>30599.418</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [104, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [343, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037930</th>\n",
       "      <td>30599.449</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [99, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [343, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037931</th>\n",
       "      <td>30599.635</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [99, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037932</th>\n",
       "      <td>30599.697</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [249, 1], [99, 3], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037933</th>\n",
       "      <td>30599.728</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [320, 8], [249, 1], [99, 3], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.893131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037934 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Timestamp Exchange                                               Bid  \\\n",
       "0            0.000    Exch0                                                []   \n",
       "1            0.279    Exch0                                          [[1, 6]]   \n",
       "2            1.333    Exch0                                          [[1, 6]]   \n",
       "3            1.581    Exch0                                          [[1, 6]]   \n",
       "4            1.643    Exch0                                          [[1, 6]]   \n",
       "...            ...      ...                                               ...   \n",
       "1037929  30599.418    Exch0            [[323, 2], [104, 3], [63, 1], [44, 6]]   \n",
       "1037930  30599.449    Exch0             [[323, 2], [99, 3], [63, 1], [44, 6]]   \n",
       "1037931  30599.635    Exch0             [[323, 2], [99, 3], [63, 1], [44, 6]]   \n",
       "1037932  30599.697    Exch0            [[323, 2], [249, 1], [99, 3], [44, 6]]   \n",
       "1037933  30599.728    Exch0  [[323, 2], [320, 8], [249, 1], [99, 3], [44, 6]]   \n",
       "\n",
       "                                                       Ask        Date  \\\n",
       "0                                                       []  2025-01-02   \n",
       "1                                                       []  2025-01-02   \n",
       "2                                               [[800, 1]]  2025-01-02   \n",
       "3                                               [[799, 1]]  2025-01-02   \n",
       "4                                               [[798, 1]]  2025-01-02   \n",
       "...                                                    ...         ...   \n",
       "1037929  [[338, 1], [343, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037930  [[338, 1], [343, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037931  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037932  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037933  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "\n",
       "         Mid_Price  Mid_Pricez-score_normalized  \n",
       "0              NaN                          NaN  \n",
       "1              NaN                          NaN  \n",
       "2            400.5                          NaN  \n",
       "3            400.0                          NaN  \n",
       "4            399.5                          NaN  \n",
       "...            ...                          ...  \n",
       "1037929      330.5                     0.893131  \n",
       "1037930      330.5                     0.893131  \n",
       "1037931      330.5                     0.893131  \n",
       "1037932      330.5                     0.893131  \n",
       "1037933      330.5                     0.893131  \n",
       "\n",
       "[1037934 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Now the df contains normalized values for features based on z-score with stats from the previous day\n",
    "samp_lob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although z-score is a common normalisation technique a number of papers suggest that different models perform better with different normalisation techniques. Given data normalisation has such and impact on model performance it can be considered during model tuning to ensure the most performant method is selected.\n",
    "\n",
    "## Create a Normalisation Function\n",
    "\n",
    "Below takes the code above and uses it in a function where different normalisation techniques can be utilised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the normalisation techniques into their own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add window size to determine the number of previous days to use in the normalisation\n",
    "# TODO Migrate this notebook to the model pipeline notebook\n",
    "\n",
    "# Define functions for the common measures required in the normalisation techniques\n",
    "\n",
    "def prev_day_mean(df, feature, prev_date):\n",
    "    \"\"\"\n",
    "    Calculate the mean of a specific feature for the previous day.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the data.\n",
    "        feature (str): The name of the feature for which the mean is calculated.\n",
    "        prev_date (str): The date for which the previous day's mean is calculated.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean of the specified feature for the previous day.\n",
    "    \"\"\"\n",
    "    prev_day_mean = df[df['Date'] == prev_date][feature].mean() # Mean of the previous day\n",
    "    return prev_day_mean\n",
    "\n",
    "def prev_day_std(df, feature, prev_date):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation of a specific feature for the previous day.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the data.\n",
    "        feature (str): The name of the feature for which the standard deviation is calculated.\n",
    "        prev_date (str): The date for which the previous day's standard deviation is calculated.\n",
    "\n",
    "    Returns:\n",
    "        float: Standard deviation of the specified feature for the previous day.\n",
    "    \"\"\"\n",
    "    prev_day_std = df[df['Date'] == prev_date][feature].std() # Standard deviation of the previous day\n",
    "    return prev_day_std\n",
    "\n",
    "def prev_day_max(df, feature, prev_date):\n",
    "    \"\"\"\n",
    "    Find the maximum value of a specific feature for the previous day.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the data.\n",
    "        feature (str): The name of the feature for which the maximum value is found.\n",
    "        prev_date (str): The date for which the previous day's maximum value is found.\n",
    "\n",
    "    Returns:\n",
    "        float: Maximum value of the specified feature for the previous day.\n",
    "    \"\"\"\n",
    "    prev_day_max = df[df['Date'] == prev_date][feature].max() # Maximum of the previous day\n",
    "    return prev_day_max\n",
    "\n",
    "def prev_day_min(df, feature, prev_date):\n",
    "    \"\"\"\n",
    "    Find the minimum value of a specific feature for the previous day.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the data.\n",
    "        feature (str): The name of the feature for which the minimum value is found.\n",
    "        prev_date (str): The date for which the previous day's minimum value is found.\n",
    "\n",
    "    Returns:\n",
    "        float: Minimum value of the specified feature for the previous day.\n",
    "    \"\"\"\n",
    "    prev_day_min = df[df['Date'] == prev_date][feature].min() # Minimum of the previous day\n",
    "    return prev_day_min\n",
    "\n",
    "def prev_day_median(df, feature, prev_date):\n",
    "    \"\"\"\n",
    "    Calculate the median of a specific feature for the previous day.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the data.\n",
    "        feature (str): The name of the feature for which the median is calculated.\n",
    "        prev_date (str): The date for which the previous day's median is calculated.\n",
    "\n",
    "    Returns:\n",
    "        float: Median of the specified feature for the previous day.\n",
    "    \"\"\"\n",
    "    prev_day_median = df[df['Date'] == prev_date][feature].median() # Median of the previous day\n",
    "    return prev_day_median\n",
    "\n",
    "def prev_day_quartiles(df, feature, prev_date):\n",
    "    \"\"\"\n",
    "    Calculate the lower and upper quartiles of a specific feature for the previous day.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the data.\n",
    "        feature (str): The name of the feature for which the quartiles are calculated.\n",
    "        prev_date (str): The date for which the previous day's quartiles are calculated.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: Series containing the lower and upper quartiles of the specified feature for the previous day.\n",
    "    \"\"\"\n",
    "    prev_day_quartiles = df[df['Date'] == prev_date][feature].quantile([0.25, 0.75]) # Upper and lower quartiles of the previous day\n",
    "    return prev_day_quartiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalisation functions to be called in the normalise_features function\n",
    "\n",
    "def z_score_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using z-score normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate mean and standard deviation.\n",
    "        date (datetime): Current date of the feature to be normalised. \n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    mean = prev_day_mean(df, feature, prev_date) # Mean of the previous day\n",
    "    std = prev_day_std(df, feature, prev_date) # Standard deviation of the previous day\n",
    "    normalised_feature = (df[df['Date'] == date][feature] - mean) / std # z-score\n",
    "    return normalised_feature\n",
    "\n",
    "def min_max_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using min-max normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate min and max.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    min_val = prev_day_min(df, feature, prev_date) # Minimum of the previous day\n",
    "    max_val = prev_day_max(df, feature, prev_date) # Maximum of the previous day\n",
    "    normalised_feature = (df[df['Date'] == date][feature] - min_val) / (max_val - min_val) # min-max\n",
    "    return normalised_feature\n",
    "\n",
    "def decimal_scaling_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using decimal scaling normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate max value.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    max_val = prev_day_max(df, feature, prev_date) # Maximum of the previous day\n",
    "    digits = len(str(abs(max_val)).split('.')[0]) # Number of digits infront of the decimal\n",
    "    normalised_feature = df[df['Date'] == date][feature] / 10**digits # decimal scaling\n",
    "    return normalised_feature\n",
    "\n",
    "def robust_scaling_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using robust scaling normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate median and interquartile range.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    prev_day_median = prev_day_median(df, feature, prev_date) # Median of the previous day\n",
    "    prev_day_quartiles = prev_day_quartiles(df, feature, prev_date) # Upper and lower quartiles of the previous day\n",
    "    prev_day_iqr = prev_day_quartiles[0.75] - prev_day_quartiles[0.25] # Inter quartile range\n",
    "    normalised_feature = (df[df['Date'] == date][feature] - prev_day_median) / prev_day_iqr # robust scaling\n",
    "    return normalised_feature\n",
    "\n",
    "def sigmoid_normalise(df, feature, prev_date, date): # TODO check this calculation\n",
    "    \"\"\"\n",
    "    Normalise the given feature using sigmoid normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate mean and standard deviation.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    prev_day_mean = prev_day_mean(df, feature, prev_date) # Mean of the previous day\n",
    "    prev_day_std = prev_day_std(df, feature, prev_date) # Standard deviation of the previous day\n",
    "    normalised_feature = 1 / (1 + np.exp((-df[df['Date'] == date][feature] - prev_day_mean) / prev_day_std)) # sigmoid\n",
    "    return normalised_feature\n",
    "\n",
    "def tanh_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using tanh normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate mean and standard deviation.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    prev_day_mean = prev_day_mean(df, feature, prev_date) # Mean of the previous day\n",
    "    prev_day_std = prev_day_std(df, feature, prev_date) # Standard deviation of the previous day\n",
    "    normalised_feature = 0.5*(np.tanh((0.01*(df[df['Date'] == date][feature] - prev_day_mean)) / prev_day_std)) # tanh estimation\n",
    "    return normalised_feature\n",
    "\n",
    "def mean_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using mean normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate mean, min, and max.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    prev_day_mean = prev_day_mean(df, feature, prev_date) # Mean of the previous day\n",
    "    min_val = prev_day_min(df, feature, prev_date) # Minimum of the previous day\n",
    "    max_val = prev_day_max(df, feature, prev_date) # Maximum of the previous day\n",
    "    normalised_feature = (df[df['Date'] == date][feature] - prev_day_mean) / (max_val - min_val) # mean normalisation\n",
    "    return normalised_feature\n",
    "\n",
    "def median_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using median normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate median and min.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    prev_day_median = prev_day_median(df, feature, prev_date) # Median of the previous day\n",
    "    min_val = prev_day_min(df, feature, prev_date) # Minimum of the previous day\n",
    "    normalised_feature = (df[df['Date'] == date][feature] - min_val) / prev_day_median # median normalisation\n",
    "    return normalised_feature\n",
    "\n",
    "def max_absolute_normalise(df, feature, prev_date, date):\n",
    "    \"\"\"\n",
    "    Normalise the given feature using max absolute normalisation.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the data.\n",
    "        feature (str): Name of the feature to normalise.\n",
    "        prev_date (datetime): Previous date to calculate max value.\n",
    "        date (datetime): Current date of the feature to be normalised.\n",
    "    \n",
    "    Returns:\n",
    "        Series: Normalised feature values.\n",
    "    \"\"\"\n",
    "    max_val = prev_day_max(df, feature, prev_date) # Maximum of the previous day\n",
    "    normalised_feature = (df[df['Date'] == date][feature]) / max_val # max absolute\n",
    "    return normalised_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the normalise_features function\n",
    "\n",
    "def normalise_features(df, features_to_normalise, method='z-score'):\n",
    "    \"\"\"\n",
    "    Normalise features in the DataFrame based on the chosen method.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame containing the LOB data and features.\n",
    "        features_to_normalise (list): List of feature column names to normalize.\n",
    "        method (str): Normalisation method. Supported methods: 'z-score', 'min-max'. Defaults to 'z-score'.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame with normalised feature columns.\n",
    "    \"\"\"\n",
    "    for date in df['Date'].unique():\n",
    "        if date == df['Date'].min():  # Skip the first date since there's no previous day\n",
    "            continue\n",
    "        \n",
    "        prev_date = df[df['Date'] < date]['Date'].max()  # Find the most recent previous date\n",
    "        \n",
    "        # Normalize the features for the current date using the chosen method\n",
    "        for feature in features_to_normalise:\n",
    "            if method == 'z-score':\n",
    "                normalised_feature = z_score_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'min-max':\n",
    "                normalised_feature = min_max_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'decimal_scaling':\n",
    "                normalised_feature = decimal_scaling_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'robust_scaling':\n",
    "                normalised_feature = robust_scaling_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'sigmoid': \n",
    "                normalised_feature = sigmoid_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'tanh': \n",
    "                normalised_feature = tanh_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'mean':\n",
    "                normalised_feature = mean_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'median':\n",
    "                normalised_feature = mean_normalise(df, feature, prev_date, date)\n",
    "            elif method == 'max_absolute':\n",
    "                normalised_feature = max_absolute_normalise(df, feature, prev_date, date)\n",
    "            # Store the normalised values in new columns\n",
    "            df.loc[df['Date'] == date, feature + '_' + method + '_normalised'] = normalised_feature\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalise = ['Mid_Price']\n",
    "\n",
    "normalised_df = normalise_features(df=samp_lob, features_to_normalise=features_to_normalise, method='decimal_scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Bid</th>\n",
       "      <th>Ask</th>\n",
       "      <th>Date</th>\n",
       "      <th>Mid_Price</th>\n",
       "      <th>Mid_Price_decimal_scaling_normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.279</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.333</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[800, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.581</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[799, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>400.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.643</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[1, 6]]</td>\n",
       "      <td>[[798, 1]]</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>399.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037929</th>\n",
       "      <td>30599.418</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [104, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [343, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037930</th>\n",
       "      <td>30599.449</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [99, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [343, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037931</th>\n",
       "      <td>30599.635</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [99, 3], [63, 1], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037932</th>\n",
       "      <td>30599.697</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [249, 1], [99, 3], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037933</th>\n",
       "      <td>30599.728</td>\n",
       "      <td>Exch0</td>\n",
       "      <td>[[323, 2], [320, 8], [249, 1], [99, 3], [44, 6]]</td>\n",
       "      <td>[[338, 1], [341, 2], [507, 4], [659, 1], [749,...</td>\n",
       "      <td>2025-01-06</td>\n",
       "      <td>330.5</td>\n",
       "      <td>0.3305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1037934 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Timestamp Exchange                                               Bid  \\\n",
       "0            0.000    Exch0                                                []   \n",
       "1            0.279    Exch0                                          [[1, 6]]   \n",
       "2            1.333    Exch0                                          [[1, 6]]   \n",
       "3            1.581    Exch0                                          [[1, 6]]   \n",
       "4            1.643    Exch0                                          [[1, 6]]   \n",
       "...            ...      ...                                               ...   \n",
       "1037929  30599.418    Exch0            [[323, 2], [104, 3], [63, 1], [44, 6]]   \n",
       "1037930  30599.449    Exch0             [[323, 2], [99, 3], [63, 1], [44, 6]]   \n",
       "1037931  30599.635    Exch0             [[323, 2], [99, 3], [63, 1], [44, 6]]   \n",
       "1037932  30599.697    Exch0            [[323, 2], [249, 1], [99, 3], [44, 6]]   \n",
       "1037933  30599.728    Exch0  [[323, 2], [320, 8], [249, 1], [99, 3], [44, 6]]   \n",
       "\n",
       "                                                       Ask        Date  \\\n",
       "0                                                       []  2025-01-02   \n",
       "1                                                       []  2025-01-02   \n",
       "2                                               [[800, 1]]  2025-01-02   \n",
       "3                                               [[799, 1]]  2025-01-02   \n",
       "4                                               [[798, 1]]  2025-01-02   \n",
       "...                                                    ...         ...   \n",
       "1037929  [[338, 1], [343, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037930  [[338, 1], [343, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037931  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037932  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "1037933  [[338, 1], [341, 2], [507, 4], [659, 1], [749,...  2025-01-06   \n",
       "\n",
       "         Mid_Price  Mid_Price_decimal_scaling_normalised  \n",
       "0              NaN                                   NaN  \n",
       "1              NaN                                   NaN  \n",
       "2            400.5                                   NaN  \n",
       "3            400.0                                   NaN  \n",
       "4            399.5                                   NaN  \n",
       "...            ...                                   ...  \n",
       "1037929      330.5                                0.3305  \n",
       "1037930      330.5                                0.3305  \n",
       "1037931      330.5                                0.3305  \n",
       "1037932      330.5                                0.3305  \n",
       "1037933      330.5                                0.3305  \n",
       "\n",
       "[1037934 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsmp-ol2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
